{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9ff96971-8ee0-4840-ade8-41afa147ead0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import timm\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "from tqdm.notebook import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torchvision.transforms as transforms\n",
    "from timm.loss import LabelSmoothingCrossEntropy\n",
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from src.dataset import get_dataloaders\n",
    "from src.PLModel import Classifier\n",
    "import src.train_utils as tu\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1ae591b8-296a-4a23-a7b8-585cdc105e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    seed = 31\n",
    "\n",
    "    # data\n",
    "    data_path = 'data'\n",
    "    \n",
    "    width = 128\n",
    "    height = 128\n",
    "    \n",
    "    # width = 224\n",
    "    # height = 224\n",
    "    \n",
    "    batch_size_train = 32\n",
    "    batch_size_val = 256\n",
    "    \n",
    "    # logger\n",
    "    version = 'multi_1e3_b_32_args_65'\n",
    "    # version = 'multistep_05_for_last5'\n",
    "    \n",
    "    # train\n",
    "    lr = 1e-3\n",
    "    workers = 16\n",
    "    max_epochs = 20\n",
    "    \n",
    "    # model\n",
    "    model_name = 'custom_batch'\n",
    "    # model_name = 'resnet18'\n",
    "    # loss_name = 'cross_entropy'\n",
    "    loss_name = 'smooth_cross_entropy'\n",
    "    loss_args = [0.34]\n",
    "    optimizer_name = 'adamw'\n",
    "    # optimizer_name = 'radam'\n",
    "    scheduler_name = 'MultiStepLR'\n",
    "    # scheduler_name = 'empty'\n",
    "    # scheduler_name = 'CyclicLR'        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fa4560-a824-4664-8d46-ccab783c94a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c588507a-ff8b-4ef1-8fe1-e46073fa5c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(height, width):\n",
    "    train_transforms_ = A.Compose([\n",
    "    A.Resize(height, width),\n",
    "    A.ColorJitter(\n",
    "        brightness=(0.65, 1.35),\n",
    "        contrast=(0.5, 1.5),\n",
    "        saturation=(0.5, 1.5), \n",
    "        hue=(-0.02, 0.02),\n",
    "        always_apply=True, p=1),\n",
    "    A.HorizontalFlip(p=0.6),\n",
    "    A.ShiftScaleRotate(scale_limit=0.05, rotate_limit=35, p=0.5),\n",
    "    A.GaussNoise(p=0.6),\n",
    "    A.Normalize(mean=(0., 0., 0.), std=(1, 1, 1)),\n",
    "    ToTensorV2()\n",
    "    ])\n",
    "    val_transforms_ = A.Compose([\n",
    "        A.Resize(height, width),\n",
    "        A.Normalize(mean=(0., 0., 0.), std=(1, 1, 1)),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "    return train_transforms_, val_transforms_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1cba8351-9b52-4768-9190-dfae32028152",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms, val_transforms = get_transforms(Config.height, Config.width)\n",
    "dl_train, dl_val = get_dataloaders(\n",
    "    Config.data_path, train_transforms, \n",
    "    val_transforms, Config.batch_size_train, \n",
    "    Config.batch_size_val, Config.workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f20ead-9141-4934-89a1-4d9a6cb557c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "593924d4-4e83-4290-b6ba-3ba43d48dd49",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n",
      "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "/home/machinelearning/.pyenv/versions/3.9.12/envs/venv_vibe/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:611: UserWarning: Checkpoint directory /home/machinelearning/projects/VladSchetko/imagenette_train/models/custom_batch/adamw_smooth_cross_entropy_multi_1e3_b_32_args_65 exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name    | Type                       | Params\n",
      "-------------------------------------------------------\n",
      "0 | model   | CustomModel                | 31.8 M\n",
      "1 | loss_fn | LabelSmoothingCrossEntropy | 0     \n",
      "-------------------------------------------------------\n",
      "31.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "31.8 M    Total params\n",
      "127.080   Total estimated model params size (MB)\n",
      "/home/machinelearning/.pyenv/versions/3.9.12/envs/venv_vibe/lib/python3.9/site-packages/pytorch_lightning/loggers/csv_logs.py:57: UserWarning: Experiment logs directory logs/custom_batch/adamw_smooth_cross_entropy_multi_1e3_b_32_args_65 exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b23b8a60debe469492276daef490eeab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 814.00 MiB (GPU 0; 23.70 GiB total capacity; 20.83 GiB already allocated; 174.56 MiB free; 21.77 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [110]\u001b[0m, in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m csv_logger, checkpoint_callback \u001b[38;5;241m=\u001b[39m tu\u001b[38;5;241m.\u001b[39mget_logger_and_checkpoint_callback(\n\u001b[1;32m     10\u001b[0m     Config\u001b[38;5;241m.\u001b[39mmodel_name, Config\u001b[38;5;241m.\u001b[39moptimizer_name,\n\u001b[1;32m     11\u001b[0m     Config\u001b[38;5;241m.\u001b[39mloss_name, Config\u001b[38;5;241m.\u001b[39mversion)\n\u001b[1;32m     13\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m     14\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39mConfig\u001b[38;5;241m.\u001b[39mmax_epochs,\n\u001b[1;32m     15\u001b[0m     gpus\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     gradient_clip_val\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m     23\u001b[0m )\n\u001b[0;32m---> 25\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m tu\u001b[38;5;241m.\u001b[39mplot_metrics(\n\u001b[1;32m     27\u001b[0m     metrics_df_path\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(csv_logger\u001b[38;5;241m.\u001b[39mlog_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetrics.csv\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     28\u001b[0m     save_path\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(csv_logger\u001b[38;5;241m.\u001b[39mlog_dir)\n\u001b[1;32m     29\u001b[0m )\n\u001b[1;32m     30\u001b[0m extra_data \u001b[38;5;241m=\u001b[39m tu\u001b[38;5;241m.\u001b[39mget_extra_data(\n\u001b[1;32m     31\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(csv_logger\u001b[38;5;241m.\u001b[39mlog_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetrics.csv\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.12/envs/venv_vibe/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:770\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;124;03mRuns the full optimization routine.\u001b[39;00m\n\u001b[1;32m    753\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;124;03m    datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.\u001b[39;00m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m--> 770\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.12/envs/venv_vibe/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:723\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 723\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;66;03m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.12/envs/venv_vibe/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:811\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    807\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m ckpt_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_ckpt_path(\n\u001b[1;32m    809\u001b[0m     ckpt_path, model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    810\u001b[0m )\n\u001b[0;32m--> 811\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.12/envs/venv_vibe/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1236\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mrestore_training_state()\n\u001b[1;32m   1234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39mresume_end()\n\u001b[0;32m-> 1236\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1238\u001b[0m log\u001b[38;5;241m.\u001b[39mdetail(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_teardown()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.12/envs/venv_vibe/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1323\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting:\n\u001b[1;32m   1322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_predict()\n\u001b[0;32m-> 1323\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.12/envs/venv_vibe/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1345\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1342\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pre_training_routine()\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1345\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;66;03m# enable train mode\u001b[39;00m\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.12/envs/venv_vibe/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1413\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1411\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[1;32m   1412\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m-> 1413\u001b[0m     \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1415\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1417\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.12/envs/venv_vibe/lib/python3.9/site-packages/pytorch_lightning/loops/base.py:204\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.12/envs/venv_vibe/lib/python3.9/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py:155\u001b[0m, in \u001b[0;36mEvaluationLoop.advance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_dataloaders \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    154\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataloader_idx\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m dataloader_idx\n\u001b[0;32m--> 155\u001b[0m dl_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl_max_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# store batch level output per dataloader\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs\u001b[38;5;241m.\u001b[39mappend(dl_outputs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.12/envs/venv_vibe/lib/python3.9/site-packages/pytorch_lightning/loops/base.py:204\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.12/envs/venv_vibe/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py:128\u001b[0m, in \u001b[0;36mEvaluationEpochLoop.advance\u001b[0;34m(self, data_fetcher, dl_max_batches, kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_started()\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# lightning module methods\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluation_step_end(output)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.12/envs/venv_vibe/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py:226\u001b[0m, in \u001b[0;36mEvaluationEpochLoop._evaluation_step\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_call_strategy_hook(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 226\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalidation_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.12/envs/venv_vibe/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1765\u001b[0m, in \u001b[0;36mTrainer._call_strategy_hook\u001b[0;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1764\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1765\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m   1768\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.12/envs/venv_vibe/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py:344\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;124;03m\"\"\"The actual validation step.\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \n\u001b[1;32m    341\u001b[0m \u001b[38;5;124;03mSee :meth:`~pytorch_lightning.core.lightning.LightningModule.validation_step` for more details\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mval_step_context():\n\u001b[0;32m--> 344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/VladSchetko/imagenette_train/src/PLModel.py:183\u001b[0m, in \u001b[0;36mClassifier.validation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidation_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, batch_idx):\n\u001b[1;32m    182\u001b[0m     images, targets \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m--> 183\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(predictions, targets)\n\u001b[1;32m    185\u001b[0m     acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macc(predictions, targets)\n",
      "File \u001b[0;32m~/projects/VladSchetko/imagenette_train/src/PLModel.py:166\u001b[0m, in \u001b[0;36mClassifier.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 166\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(x)\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.12/envs/venv_vibe/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects/VladSchetko/imagenette_train/src/PLModel.py:51\u001b[0m, in \u001b[0;36mCustomModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 51\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten(x)\n\u001b[1;32m     53\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_ln(x)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.12/envs/venv_vibe/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.12/envs/venv_vibe/lib/python3.9/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.12/envs/venv_vibe/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.12/envs/venv_vibe/lib/python3.9/site-packages/torch/nn/modules/conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.12/envs/venv_vibe/lib/python3.9/site-packages/torch/nn/modules/conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    451\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    452\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 814.00 MiB (GPU 0; 23.70 GiB total capacity; 20.83 GiB already allocated; 174.56 MiB free; 21.77 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "classifier = Classifier(\n",
    "    Config.model_name, \n",
    "    Config.loss_name, \n",
    "    Config.loss_args,\n",
    "    Config.optimizer_name, \n",
    "    Config.scheduler_name, \n",
    "    lr=Config.lr)\n",
    "\n",
    "csv_logger, checkpoint_callback = tu.get_logger_and_checkpoint_callback(\n",
    "    Config.model_name, Config.optimizer_name,\n",
    "    Config.loss_name, Config.version)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=Config.max_epochs,\n",
    "    gpus=1,\n",
    "    # precision=16,\n",
    "    limit_train_batches=1.0, \n",
    "    limit_val_batches=1.0,\n",
    "    val_check_interval=1.0,\n",
    "    logger=csv_logger,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    gradient_clip_val=0.5\n",
    ")\n",
    "\n",
    "trainer.fit(classifier, dl_train, dl_val)\n",
    "tu.plot_metrics(\n",
    "    metrics_df_path=os.path.join(csv_logger.log_dir, 'metrics.csv'),\n",
    "    save_path=os.path.join(csv_logger.log_dir)\n",
    ")\n",
    "extra_data = tu.get_extra_data(\n",
    "    os.path.join(csv_logger.log_dir, 'metrics.csv'))\n",
    "print('best cal acc', extra_data['val_acc']['max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a13b4f-4bb7-4dcb-8e97-5d395b1c865b",
   "metadata": {},
   "source": [
    "## Overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "18f3d523-2dff-415b-b2f3-5ca1fdb0bb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from src.PLModel import model_factory, optimizer_factory, loss_factory, calculate_accuracy\n",
    "\n",
    "overfit_batch = next(iter(dl_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "658c581e-553a-4082-b427-9b1aae587761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac1e772bf9c4c8cb28af940bf545319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.69 GiB (GPU 0; 23.70 GiB total capacity; 20.25 GiB already allocated; 174.56 MiB free; 21.77 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [108]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m pbar \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28mrange\u001b[39m(n_iterations))\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[0;32m---> 18\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     acc \u001b[38;5;241m=\u001b[39m calculate_accuracy(predictions, targets)\n\u001b[1;32m     20\u001b[0m     acc_history\u001b[38;5;241m.\u001b[39mappend(acc\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.12/envs/venv_vibe/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects/VladSchetko/imagenette_train/src/PLModel.py:51\u001b[0m, in \u001b[0;36mCustomModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 51\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten(x)\n\u001b[1;32m     53\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_ln(x)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.12/envs/venv_vibe/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.12/envs/venv_vibe/lib/python3.9/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.12/envs/venv_vibe/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.12/envs/venv_vibe/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py:168\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.12/envs/venv_vibe/lib/python3.9/site-packages/torch/nn/functional.py:2438\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2436\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2438\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2439\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2440\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.69 GiB (GPU 0; 23.70 GiB total capacity; 20.25 GiB already allocated; 174.56 MiB free; 21.77 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "model = model_factory(Config.model_name)\n",
    "\n",
    "opt = optimizer_factory(Config.optimizer_name)(model.parameters(), lr=Config.lr)\n",
    "n_iterations = Config.max_epochs\n",
    "# n_iterations = 100\n",
    "input_images, targets = overfit_batch\n",
    "\n",
    "model.to('cuda:0')\n",
    "input_images = input_images.to('cuda:0')\n",
    "targets = targets.to('cuda:0')\n",
    "loss = loss_factory(Config.loss_name)\n",
    "loss_history = []\n",
    "acc_history = []\n",
    "\n",
    "pbar = tqdm(range(n_iterations))\n",
    "\n",
    "for _ in pbar:\n",
    "    predictions = model(input_images)\n",
    "    acc = calculate_accuracy(predictions, targets)\n",
    "    acc_history.append(acc.item())\n",
    "    loss_value = loss(predictions, targets)\n",
    "    loss_history.append(loss_value.item())\n",
    "    pbar.set_description(f\"Loss {loss_value.item()}, Acc {acc.item()}\")\n",
    "    opt.zero_grad()\n",
    "    loss_value.backward()\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39ecfb6c-90e8-409d-b332-75f9f86de403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7dc4fb9a30>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9088640b-6ce7-4fb3-9d89-5e372fd996e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7dc4f53250>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(acc_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd8e8f0-a62e-408e-82a7-d6a494e3f270",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2ffcd6e-f10b-41b0-999e-027a16004a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model('resnet50', num_classes=10, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e0343a8e-952e-4d18-8b16-3deccf4f0f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels=(3, 16, 16, 32, 64),\n",
    "        kernel_size=(5, 5, 5, 3),\n",
    "        batch_norm=True,\n",
    "        dropout_p=0,\n",
    "        max_pool_kernel=5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.fe = nn.Sequential()\n",
    "\n",
    "        for i in range(len(channels) - 2):\n",
    "            self.fe.append(\n",
    "                nn.Conv2d(channels[i], channels[i + 1],\n",
    "                          kernel_size[i],\n",
    "                          stride=1))\n",
    "            if batch_norm:\n",
    "                self.fe.append(nn.BatchNorm2d(channels[i + 1]))\n",
    "            self.fe.append(nn.ReLU())\n",
    "            if dropout_p:\n",
    "                self.fe.append(nn.Dropout(p=dropout_p))\n",
    "        self.fe.append(nn.Conv2d(channels[-2], channels[-1],\n",
    "                                 kernel_size[-1],\n",
    "                                 stride=1))\n",
    "        if batch_norm:\n",
    "            self.fe.append(nn.BatchNorm2d(channels[-1]))\n",
    "        if max_pool_kernel:\n",
    "            self.fe.append(nn.MaxPool2d(max_pool_kernel))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.input_ln = nn.Linear(30976, 1024)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output_ln = nn.Linear(1024, 10) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fe(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.input_ln(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output_ln(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "de7ae110-007b-4d05-a101-a35b1fac9929",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7ead0afd-7331-441d-9066-195111310ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.randn(1, 3, 128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7d0e5551-0e4a-4f37-94fd-494623c61ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(t).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vibe-venv",
   "language": "python",
   "name": "vibe-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
